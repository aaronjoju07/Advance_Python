{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('all')\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize,WordPunctTokenizer,TreebankWordTokenizer,RegexpTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "given_string = \"\"\"\"Dr. Devi ShettyLabs Limited stands tall within the Great Namaste Towers, offering cutting-edge healthcare services. As the company's network security engineer, you are tasked with designing and implementing a secure healthcare information network system that ensures confidentiality, integrity, and availability of data and communication. With user counts expected to double by 2025, scalability is a critical consideration. Leveraging Cisco Packet Tracer, you'll employ a hierarchical design model, incorporating redundancy for resilience. The network will feature distinct segments for LAN, WLAN, Voice, and DMZ, each with designated IP address ranges. Cisco routers and switches, along with a Cisco ASA Firewall, will fortify the network's security, while Voice over IP (VoIP) capabilities and Wireless LAN Controllers (WLC) will enhance communication efficiency. Thorough testing will validate the network's performance, meeting the company's stringent requirements for reliability and scalability in delivering top-tier healthcare services.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I cant allow you  to go home early']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(\"I cant allow you  to go home early\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Dr. Devi ShettyLabs Limited stands tall within the Great Namaste Towers, offering cutting-edge healthcare services.',\n",
       " \"As the company's network security engineer, you are tasked with designing and implementing a secure healthcare information network system that ensures confidentiality, integrity, and availability of data and communication.\",\n",
       " 'With user counts expected to double by 2025, scalability is a critical consideration.',\n",
       " \"Leveraging Cisco Packet Tracer, you'll employ a hierarchical design model, incorporating redundancy for resilience.\",\n",
       " 'The network will feature distinct segments for LAN, WLAN, Voice, and DMZ, each with designated IP address ranges.',\n",
       " \"Cisco routers and switches, along with a Cisco ASA Firewall, will fortify the network's security, while Voice over IP (VoIP) capabilities and Wireless LAN Controllers (WLC) will enhance communication efficiency.\",\n",
       " \"Thorough testing will validate the network's performance, meeting the company's stringent requirements for reliability and scalability in delivering top-tier healthcare services.\"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(given_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1046"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(given_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'ca', \"n't\", 'allow', 'you', 'to', 'go', 'home', 'early']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(\"I can't allow you  to go home early\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'can', \"'\", 't', 'allow', 'you', 'to', 'go', 'home', 'early']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordPunctTokenizer().tokenize(\"I can't allow you  to go home early\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'ca', \"n't\", 'allow', 'you', 'to', 'go', 'home', 'early']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TreebankWordTokenizer().tokenize(\"I can't allow you  to go home early\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', \"can't\", 'allow', 'you', 'to', 'go', 'home', 'early']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizee = RegexpTokenizer(\"[\\w']+\")\n",
    "tokenizee.tokenize(\"I can't allow you  to go home early.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "['\"', 'r', '.', ' ', 'e', 'v', ' ', 'h', 'e', 'L', 'b', ' ', 'L', 'e', ' ', 'n', ' ', 'l', 'l', ' ', 'w', 'h', 'n', ' ', 'h', 'e', ' ', 'G', 'r', 'e', ' ', 'N', 'e', ' ', 'w', 'e', 'r', ',', ' ', 'f', 'f', 'e', 'r', 'n', 'g', ' ', 'c', 'u', 'n', 'g', '-', 'e', 'g', 'e', ' ', 'h', 'e', 'l', 'h', 'c', 'r', 'e', ' ', 'e', 'r', 'v', 'c', 'e', '.', ' ', ' ', 'h', 'e', ' ', 'c', 'p', 'n', \"'\", ' ', 'n', 'e', 'w', 'r', 'k', ' ', 'e', 'c', 'u', 'r', ' ', 'e', 'n', 'g', 'n', 'e', 'e', 'r', ',', ' ', 'u', ' ', 'r', 'e', ' ', 'k', 'e', ' ', 'w', 'h', ' ', 'e', 'g', 'n', 'n', 'g', ' ', 'n', ' ', 'p', 'l', 'e', 'e', 'n', 'n', 'g', ' ', ' ', 'e', 'c', 'u', 'r', 'e', ' ', 'h', 'e', 'l', 'h', 'c', 'r', 'e', ' ', 'n', 'f', 'r', 'n', ' ', 'n', 'e', 'w', 'r', 'k', ' ', 'e', ' ', 'h', ' ', 'e', 'n', 'u', 'r', 'e', ' ', 'c', 'n', 'f', 'e', 'n', 'l', ',', ' ', 'n', 'e', 'g', 'r', ',', ' ', 'n', ' ', 'v', 'l', 'b', 'l', ' ', 'f', ' ', ' ', 'n', ' ', 'c', 'u', 'n', 'c', 'n', '.', ' ', 'W', 'h', ' ', 'u', 'e', 'r', ' ', 'c', 'u', 'n', ' ', 'e', 'x', 'p', 'e', 'c', 'e', ' ', ' ', 'u', 'b', 'l', 'e', ' ', 'b', ' ', '2', '0', '2', '5', ',', ' ', 'c', 'l', 'b', 'l', ' ', ' ', ' ', 'c', 'r', 'c', 'l', ' ', 'c', 'n', 'e', 'r', 'n', '.', ' ', 'L', 'e', 'v', 'e', 'r', 'g', 'n', 'g', ' ', 'C', 'c', ' ', 'P', 'c', 'k', 'e', ' ', 'r', 'c', 'e', 'r', ',', ' ', 'u', \"'\", 'l', 'l', ' ', 'e', 'p', 'l', ' ', ' ', 'h', 'e', 'r', 'r', 'c', 'h', 'c', 'l', ' ', 'e', 'g', 'n', ' ', 'e', 'l', ',', ' ', 'n', 'c', 'r', 'p', 'r', 'n', 'g', ' ', 'r', 'e', 'u', 'n', 'n', 'c', ' ', 'f', 'r', ' ', 'r', 'e', 'l', 'e', 'n', 'c', 'e', '.', ' ', 'h', 'e', ' ', 'n', 'e', 'w', 'r', 'k', ' ', 'w', 'l', 'l', ' ', 'f', 'e', 'u', 'r', 'e', ' ', 'n', 'c', ' ', 'e', 'g', 'e', 'n', ' ', 'f', 'r', ' ', 'L', 'N', ',', ' ', 'W', 'L', 'N', ',', ' ', 'V', 'c', 'e', ',', ' ', 'n', ' ', 'Z', ',', ' ', 'e', 'c', 'h', ' ', 'w', 'h', ' ', 'e', 'g', 'n', 'e', ' ', 'P', ' ', 'r', 'e', ' ', 'r', 'n', 'g', 'e', '.', ' ', 'C', 'c', ' ', 'r', 'u', 'e', 'r', ' ', 'n', ' ', 'w', 'c', 'h', 'e', ',', ' ', 'l', 'n', 'g', ' ', 'w', 'h', ' ', ' ', 'C', 'c', ' ', ' ', 'F', 'r', 'e', 'w', 'l', 'l', ',', ' ', 'w', 'l', 'l', ' ', 'f', 'r', 'f', ' ', 'h', 'e', ' ', 'n', 'e', 'w', 'r', 'k', \"'\", ' ', 'e', 'c', 'u', 'r', ',', ' ', 'w', 'h', 'l', 'e', ' ', 'V', 'c', 'e', ' ', 'v', 'e', 'r', ' ', 'P', ' ', '(', 'V', 'P', ')', ' ', 'c', 'p', 'b', 'l', 'e', ' ', 'n', ' ', 'W', 'r', 'e', 'l', 'e', ' ', 'L', 'N', ' ', 'C', 'n', 'r', 'l', 'l', 'e', 'r', ' ', '(', 'W', 'L', 'C', ')', ' ', 'w', 'l', 'l', ' ', 'e', 'n', 'h', 'n', 'c', 'e', ' ', 'c', 'u', 'n', 'c', 'n', ' ', 'e', 'f', 'f', 'c', 'e', 'n', 'c', '.', ' ', 'h', 'r', 'u', 'g', 'h', ' ', 'e', 'n', 'g', ' ', 'w', 'l', 'l', ' ', 'v', 'l', 'e', ' ', 'h', 'e', ' ', 'n', 'e', 'w', 'r', 'k', \"'\", ' ', 'p', 'e', 'r', 'f', 'r', 'n', 'c', 'e', ',', ' ', 'e', 'e', 'n', 'g', ' ', 'h', 'e', ' ', 'c', 'p', 'n', \"'\", ' ', 'r', 'n', 'g', 'e', 'n', ' ', 'r', 'e', 'q', 'u', 'r', 'e', 'e', 'n', ' ', 'f', 'r', ' ', 'r', 'e', 'l', 'b', 'l', ' ', 'n', ' ', 'c', 'l', 'b', 'l', ' ', 'n', ' ', 'e', 'l', 'v', 'e', 'r', 'n', 'g', ' ', 'p', '-', 'e', 'r', ' ', 'h', 'e', 'l', 'h', 'c', 'r', 'e', ' ', 'e', 'r', 'v', 'c', 'e', '.']\n",
      "1046\n",
      "643\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))\n",
    "given_text = word_tokenize(\"I can't allow you  to go home early\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "filtered_text = []\n",
    "for word in given_string:\n",
    "    if word.casefold() not in stop_words:\n",
    "        filtered_text.append(word)\n",
    "print(filtered_text)\n",
    "print(len(given_string))\n",
    "print(len(filtered_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['``', 'Dr.', 'Devi', 'ShettyLabs', 'Limited', 'stands', 'tall', 'within', 'the', 'Great', 'Namaste', 'Towers', ',', 'offering', 'cutting-edge', 'healthcare', 'services', '.', 'As', 'the', 'company', \"'s\", 'network', 'security', 'engineer', ',', 'you', 'are', 'tasked', 'with', 'designing', 'and', 'implementing', 'a', 'secure', 'healthcare', 'information', 'network', 'system', 'that', 'ensures', 'confidentiality', ',', 'integrity', ',', 'and', 'availability', 'of', 'data', 'and', 'communication', '.', 'With', 'user', 'counts', 'expected', 'to', 'double', 'by', '2025', ',', 'scalability', 'is', 'a', 'critical', 'consideration', '.', 'Leveraging', 'Cisco', 'Packet', 'Tracer', ',', 'you', \"'ll\", 'employ', 'a', 'hierarchical', 'design', 'model', ',', 'incorporating', 'redundancy', 'for', 'resilience', '.', 'The', 'network', 'will', 'feature', 'distinct', 'segments', 'for', 'LAN', ',', 'WLAN', ',', 'Voice', ',', 'and', 'DMZ', ',', 'each', 'with', 'designated', 'IP', 'address', 'ranges', '.', 'Cisco', 'routers', 'and', 'switches', ',', 'along', 'with', 'a', 'Cisco', 'ASA', 'Firewall', ',', 'will', 'fortify', 'the', 'network', \"'s\", 'security', ',', 'while', 'Voice', 'over', 'IP', '(', 'VoIP', ')', 'capabilities', 'and', 'Wireless', 'LAN', 'Controllers', '(', 'WLC', ')', 'will', 'enhance', 'communication', 'efficiency', '.', 'Thorough', 'testing', 'will', 'validate', 'the', 'network', \"'s\", 'performance', ',', 'meeting', 'the', 'company', \"'s\", 'stringent', 'requirements', 'for', 'reliability', 'and', 'scalability', 'in', 'delivering', 'top-tier', 'healthcare', 'services', '.']\n",
      "['``', 'dr.', 'devi', 'shettylab', 'limit', 'stand', 'tall', 'within', 'the', 'great', 'namast', 'tower', ',', 'offer', 'cutting-edg', 'healthcar', 'servic', '.', 'as', 'the', 'compani', \"'s\", 'network', 'secur', 'engin', ',', 'you', 'are', 'task', 'with', 'design', 'and', 'implement', 'a', 'secur', 'healthcar', 'inform', 'network', 'system', 'that', 'ensur', 'confidenti', ',', 'integr', ',', 'and', 'avail', 'of', 'data', 'and', 'commun', '.', 'with', 'user', 'count', 'expect', 'to', 'doubl', 'by', '2025', ',', 'scalabl', 'is', 'a', 'critic', 'consider', '.', 'leverag', 'cisco', 'packet', 'tracer', ',', 'you', \"'ll\", 'employ', 'a', 'hierarch', 'design', 'model', ',', 'incorpor', 'redund', 'for', 'resili', '.', 'the', 'network', 'will', 'featur', 'distinct', 'segment', 'for', 'lan', ',', 'wlan', ',', 'voic', ',', 'and', 'dmz', ',', 'each', 'with', 'design', 'ip', 'address', 'rang', '.', 'cisco', 'router', 'and', 'switch', ',', 'along', 'with', 'a', 'cisco', 'asa', 'firewal', ',', 'will', 'fortifi', 'the', 'network', \"'s\", 'secur', ',', 'while', 'voic', 'over', 'ip', '(', 'voip', ')', 'capabl', 'and', 'wireless', 'lan', 'control', '(', 'wlc', ')', 'will', 'enhanc', 'commun', 'effici', '.', 'thorough', 'test', 'will', 'valid', 'the', 'network', \"'s\", 'perform', ',', 'meet', 'the', 'compani', \"'s\", 'stringent', 'requir', 'for', 'reliabl', 'and', 'scalabl', 'in', 'deliv', 'top-tier', 'healthcar', 'servic', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "words = word_tokenize(given_string)\n",
    "print(words)\n",
    "stemmed_word = [stemmer.stem(word) for word in words]\n",
    "print(stemmed_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks : rock\n",
      "corpora : corpus\n",
      "better : better\n",
      "better : good\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatization = WordNetLemmatizer()\n",
    "print(\"rocks :\",lemmatization.lemmatize(\"rocks\"))\n",
    "print(\"corpora :\",lemmatization.lemmatize(\"corpora\"))\n",
    "print(\"better :\",lemmatization.lemmatize(\"better\"))\n",
    "print(\"better :\",lemmatization.lemmatize(\"better\",pos=\"a\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
